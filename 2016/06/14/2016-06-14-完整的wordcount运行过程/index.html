<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="hadoop," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="下面是一个完整的在Hadoop环境下运行WordCount的程序，相关命令以及在使用过程中遇到的问题都有详细的说明
前提：已经在本机正确部署了Hadoop环境（单机或者伪分布式都可以）
相比起直接在eclipse中运行，这个更有意义，也更有成就感
本文参考了Hadoop官方文档MapReduceTutorial">
<meta property="og:type" content="article">
<meta property="og:title" content="完整的wordcount运行过程">
<meta property="og:url" content="http://liuyiyou.cn/2016/06/14/2016-06-14-完整的wordcount运行过程/index.html">
<meta property="og:site_name" content="温故而知新    触类而旁通">
<meta property="og:description" content="下面是一个完整的在Hadoop环境下运行WordCount的程序，相关命令以及在使用过程中遇到的问题都有详细的说明
前提：已经在本机正确部署了Hadoop环境（单机或者伪分布式都可以）
相比起直接在eclipse中运行，这个更有意义，也更有成就感
本文参考了Hadoop官方文档MapReduceTutorial">
<meta property="og:updated_time" content="2017-04-14T07:41:07.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="完整的wordcount运行过程">
<meta name="twitter:description" content="下面是一个完整的在Hadoop环境下运行WordCount的程序，相关命令以及在使用过程中遇到的问题都有详细的说明
前提：已经在本机正确部署了Hadoop环境（单机或者伪分布式都可以）
相比起直接在eclipse中运行，这个更有意义，也更有成就感
本文参考了Hadoop官方文档MapReduceTutorial">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://liuyiyou.cn/2016/06/14/2016-06-14-完整的wordcount运行过程/"/>





  <title> 完整的wordcount运行过程 | 温故而知新    触类而旁通 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">温故而知新    触类而旁通</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">liuyiyou的个人小站</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-inbox">
          <a href="/inbox" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-inbox"></i> <br />
            
            收藏
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://liuyiyou.cn/2016/06/14/2016-06-14-完整的wordcount运行过程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="liuyiyou">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="温故而知新    触类而旁通">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                完整的wordcount运行过程
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-06-14T08:00:00+08:00">
                2016-06-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>下面是一个完整的在Hadoop环境下运行WordCount的程序，相关命令以及在使用过程中遇到的问题都有详细的说明</p>
<p>前提：已经在本机正确部署了Hadoop环境（单机或者伪分布式都可以）</p>
<p>相比起直接在eclipse中运行，这个更有意义，也更有成就感</p>
<p>本文参考了Hadoop官方文档<a href="file:///Users/liuyiyou/Desktop/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Purpose" target="_blank" rel="external">MapReduceTutorial</a></p>
<a id="more"></a>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs fs -mkdir liuyiyou</span><br><span class="line">错误: 找不到或无法加载主类 fs 的  （这里是因为没有设置环境变量或者没有将tools.jar复制到hadoop中，具体可以参考环境变量设置和tools.jar的位置。）</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -mkdir liuyiyou （设置HDFS目录，可以通过相关命令进行查看）</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">12</span> <span class="number">17</span>:<span class="number">50</span>:<span class="number">43</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">mkdir: `liuyiyou<span class="string">': No such file or directory</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs  -copyFromLocal input/test.txt /user/liuyiyou/test.txt（将本地文件复制到HDFS目录中）</span><br><span class="line">16/02/12 17:51:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">copyFromLocal: `/user/liuyiyou/test.txt'</span>: No such file or directory</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs  -copyFromLocal input/test.txt /liuyiyou/test.txt</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">12</span> <span class="number">17</span>:<span class="number">52</span>:<span class="number">39</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">copyFromLocal: `/liuyiyou/test.txt<span class="string">': No such file or directory</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -mkdir /user</span><br><span class="line">16/02/12 17:53:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -mkdir /user/liuyiyou</span><br><span class="line">16/02/12 17:54:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs  -copyFromLocal input/test.txt /user/liuyiyou/test.txt</span><br><span class="line">16/02/12 17:54:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -ls                  （查看HDFS目录中的文件）</span><br><span class="line">16/02/12 17:55:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 liuyiyou supergroup        774 2016-02-12 17:54 test.txt</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -ls .（查看HDFS目录中的文件）</span><br><span class="line">16/02/12 17:56:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 liuyiyou supergroup        774 2016-02-12 17:54 test.txt</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs -mkdir books</span><br><span class="line">Unrecognized option: -mkdir</span><br><span class="line">Error: Could not create the Java Virtual Machine.</span><br><span class="line">Error: A fatal exception has occurred. Program will exit.</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -mkdir books</span><br><span class="line">16/02/12 17:58:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -ls .</span><br><span class="line">16/02/12 17:58:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - liuyiyou supergroup          0 2016-02-12 17:58 books</span><br><span class="line">-rw-r--r--   1 liuyiyou supergroup        774 2016-02-12 17:54 test.txt</span><br><span class="line"></span><br><span class="line">（这里开始运行文档中的WordCount程序）</span><br><span class="line"></span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sum.tools.javac.Main WordCount.java</span><br><span class="line">错误: 找不到或无法加载主类 com.sum.tools.javac.Main（需要设置环境变量或者复制tools.jar到hadoop中）</span><br><span class="line">➜  hadoop-2.6.0  cd ~</span><br><span class="line">➜  ~  source .bash_profile</span><br><span class="line">➜  ~  cd hadoop-2.6.0</span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sum.tools.javac.Main WordCount.java</span><br><span class="line">错误: 找不到或无法加载主类 com.sum.tools.javac.Main</span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sum.tools.javac.Main WordCount.java</span><br><span class="line">错误: 找不到或无法加载主类 com.sum.tools.javac.Main</span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sum.tools.javac.Main WordCount.java</span><br><span class="line">错误: 找不到或无法加载主类 com.sum.tools.javac.Main</span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sum.tools.javac.Main WordCount.java</span><br><span class="line">错误: 找不到或无法加载主类 com.sum.tools.javac.Main</span><br><span class="line"></span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop com.sun.tools.javac.Main WordCount.java（这里已经设置好之后不报错，编译程序）</span><br><span class="line">➜  hadoop-2.6.0  jar cf wc.jar WordCount*.class（打包程序）</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -mkdir /user/joe/wordcount/input（设置HDFS输入目录，只能逐个设置）</span><br><span class="line">16/02/13 01:27:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">mkdir: `/user/joe/wordcount/input'</span>: No such file or directory</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -mkdir /user/joe/</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">27</span>:<span class="number">55</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -mkdir /user/joe/wordcount</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">28</span>:<span class="number">19</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -mkdir /user/joe/wordcount/input（设置HDFS目录完成）</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">28</span>:<span class="number">40</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -mkdir /user/joe/wordcount/output（这里不需要设置，输出如果没有，会自动生成，这样导致后面又将该目录删除了）</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">29</span>:<span class="number">03</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs  -copyFromLocal input/file01 /user/joe/wordcount/input（将本地文件复制到HDFS目录）</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">33</span>:<span class="number">04</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs  -copyFromLocal input/file02 /user/joe/wordcount/input</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">33</span>:<span class="number">38</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hadoop jar wc.jar WordCount /user/joe/wordcount/input /user/joe/wordcount/output（运行程序失败，原因是output目录已经存在）</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">34</span>:<span class="number">10</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">34</span>:<span class="number">10</span> INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">34</span>:<span class="number">10</span> INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">"main"</span> org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:<span class="number">9000</span>/user/joe/wordcount/output already exists</span><br><span class="line">at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:<span class="number">146</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:<span class="number">562</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:<span class="number">432</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job<span class="variable">$10</span>.run(Job.java:<span class="number">1296</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job<span class="variable">$10</span>.run(Job.java:<span class="number">1293</span>)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:<span class="number">1628</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.submit(Job.java:<span class="number">1293</span>)</span><br><span class="line">at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:<span class="number">1314</span>)</span><br><span class="line">at WordCount.main(WordCount.java:<span class="number">59</span>)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line">at org.apache.hadoop.util.RunJar.run(RunJar.java:<span class="number">221</span>)</span><br><span class="line">at org.apache.hadoop.util.RunJar.main(RunJar.java:<span class="number">136</span>)</span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -remove /user/joe/wordcount/output</span><br><span class="line">-remove: Unknown <span class="built_in">command</span></span><br><span class="line">➜  hadoop-<span class="number">2.6</span>.<span class="number">0</span>  bin/hdfs dfs -rm /user/joe/wordcount/output（删除output目录，但是失败）</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>/<span class="number">02</span>/<span class="number">13</span> <span class="number">01</span>:<span class="number">38</span>:<span class="number">18</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using <span class="built_in">builtin</span>-java classes <span class="built_in">where</span> applicable</span><br><span class="line">rm: `/user/joe/wordcount/output<span class="string">': Is a directory</span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -rm -R  /user/joe/wordcount/output（删除成功）</span><br><span class="line"></span><br><span class="line">16/02/13 01:39:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">16/02/13 01:39:16 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.</span><br><span class="line">Deleted /user/joe/wordcount/output</span><br><span class="line">➜  hadoop-2.6.0  bin/hadoop jar wc.jar WordCount /user/joe/wordcount/input /user/joe/wordcount/output（运行成功）</span><br><span class="line"></span><br><span class="line">16/02/13 01:39:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">16/02/13 01:39:47 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line">16/02/13 01:39:47 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">16/02/13 01:39:47 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.</span><br><span class="line">16/02/13 01:39:47 INFO input.FileInputFormat: Total input paths to process : 2</span><br><span class="line">16/02/13 01:39:47 INFO mapreduce.JobSubmitter: number of splits:2</span><br><span class="line">16/02/13 01:39:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local108329066_0001</span><br><span class="line">16/02/13 01:39:48 INFO mapreduce.Job: The url to track the job: http://localhost:8080/</span><br><span class="line">16/02/13 01:39:48 INFO mapreduce.Job: Running job: job_local108329066_0001</span><br><span class="line">16/02/13 01:39:48 INFO mapred.LocalJobRunner: OutputCommitter set in config null</span><br><span class="line">16/02/13 01:39:48 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter</span><br><span class="line">16/02/13 01:39:48 INFO mapred.LocalJobRunner: Waiting for map tasks</span><br><span class="line">16/02/13 01:39:48 INFO mapred.LocalJobRunner: Starting task: attempt_local108329066_0001_m_000000_0</span><br><span class="line">16/02/13 01:39:48 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.</span><br><span class="line">16/02/13 01:39:48 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/joe/wordcount/input/file02:0+27</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: soft limit at 83886080</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: kvstart = 26214396; length = 6553600</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line">16/02/13 01:39:48 INFO mapred.LocalJobRunner:</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: Starting flush of map output</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: Spilling map output</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: bufstart = 0; bufend = 44; bufvoid = 104857600</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600</span><br><span class="line">16/02/13 01:39:48 INFO mapred.MapTask: Finished spill 0</span><br><span class="line">16/02/13 01:39:48 INFO mapred.Task: Task:attempt_local108329066_0001_m_000000_0 is done. And is in the process of committing</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: map</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task '</span>attempt_<span class="built_in">local</span>108329066_0001_m_000000_0<span class="string">' done.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Finishing task: attempt_local108329066_0001_m_000000_0</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Starting task: attempt_local108329066_0001_m_000001_0</span><br><span class="line">16/02/13 01:39:49 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/joe/wordcount/input/file01:0+21</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: soft limit at 83886080</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: kvstart = 26214396; length = 6553600</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner:</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: Starting flush of map output</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: Spilling map output</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: bufstart = 0; bufend = 38; bufvoid = 104857600</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600</span><br><span class="line">16/02/13 01:39:49 INFO mapred.MapTask: Finished spill 0</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task:attempt_local108329066_0001_m_000001_0 is done. And is in the process of committing</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: map</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task '</span>attempt_<span class="built_in">local</span>108329066_0001_m_000001_0<span class="string">' done.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Finishing task: attempt_local108329066_0001_m_000001_0</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: map task executor complete.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Waiting for reduce tasks</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Starting task: attempt_local108329066_0001_r_000000_0</span><br><span class="line">16/02/13 01:39:49 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null</span><br><span class="line">16/02/13 01:39:49 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a24b738</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=333971456, maxSingleShuffleLimit=83492864, mergeThreshold=220421168, ioSortFactor=10, memToMemMergeOutputsThreshold=10</span><br><span class="line">16/02/13 01:39:49 INFO reduce.EventFetcher: attempt_local108329066_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events</span><br><span class="line">16/02/13 01:39:49 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local108329066_0001_m_000000_0 decomp: 41 len: 45 to MEMORY</span><br><span class="line">16/02/13 01:39:49 INFO reduce.InMemoryMapOutput: Read 41 bytes from map-output for attempt_local108329066_0001_m_000000_0</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 41, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;41</span><br><span class="line">16/02/13 01:39:49 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local108329066_0001_m_000001_0 decomp: 36 len: 40 to MEMORY</span><br><span class="line">16/02/13 01:39:49 INFO reduce.InMemoryMapOutput: Read 36 bytes from map-output for attempt_local108329066_0001_m_000001_0</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 36, inMemoryMapOutputs.size() -&gt; 2, commitMemory -&gt; 41, usedMemory -&gt;77</span><br><span class="line">16/02/13 01:39:49 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: 2 / 2 copied.</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Merger: Merging 2 sorted segments</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 61 bytes</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: Merged 2 segments, 77 bytes to disk to satisfy reduce memory limit</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: Merging 1 files, 79 bytes from disk</span><br><span class="line">16/02/13 01:39:49 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Merger: Merging 1 sorted segments</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 69 bytes</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: 2 / 2 copied.</span><br><span class="line">16/02/13 01:39:49 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task:attempt_local108329066_0001_r_000000_0 is done. And is in the process of committing</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: 2 / 2 copied.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task attempt_local108329066_0001_r_000000_0 is allowed to commit now</span><br><span class="line">16/02/13 01:39:49 INFO output.FileOutputCommitter: Saved output of task '</span>attempt_<span class="built_in">local</span>108329066_0001_r_000000_0<span class="string">' to hdfs://localhost:9000/user/joe/wordcount/output/_temporary/0/task_local108329066_0001_r_000000</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: reduce &gt; reduce</span><br><span class="line">16/02/13 01:39:49 INFO mapred.Task: Task '</span>attempt_<span class="built_in">local</span>108329066_0001_r_000000_0<span class="string">' done.</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: Finishing task: attempt_local108329066_0001_r_000000_0</span><br><span class="line">16/02/13 01:39:49 INFO mapred.LocalJobRunner: reduce task executor complete.</span><br><span class="line">16/02/13 01:39:49 INFO mapreduce.Job: Job job_local108329066_0001 running in uber mode : false</span><br><span class="line">16/02/13 01:39:49 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">16/02/13 01:39:49 INFO mapreduce.Job: Job job_local108329066_0001 completed successfully</span><br><span class="line">16/02/13 01:39:49 INFO mapreduce.Job: Counters: 35</span><br><span class="line">File System Counters</span><br><span class="line">FILE: Number of bytes read=10860</span><br><span class="line"></span><br><span class="line">FILE: Number of bytes written=772228</span><br><span class="line"></span><br><span class="line">FILE: Number of read operations=0</span><br><span class="line"></span><br><span class="line">FILE: Number of large read operations=0</span><br><span class="line"></span><br><span class="line">FILE: Number of write operations=0</span><br><span class="line"></span><br><span class="line">HDFS: Number of bytes read=123</span><br><span class="line"></span><br><span class="line">HDFS: Number of bytes written=41</span><br><span class="line"></span><br><span class="line">HDFS: Number of read operations=25</span><br><span class="line"></span><br><span class="line">HDFS: Number of large read operations=0</span><br><span class="line"></span><br><span class="line">HDFS: Number of write operations=5</span><br><span class="line"></span><br><span class="line">Map-Reduce Framework</span><br><span class="line">Map input records=2</span><br><span class="line"></span><br><span class="line">Map output records=8</span><br><span class="line"></span><br><span class="line">Map output bytes=82</span><br><span class="line"></span><br><span class="line">Map output materialized bytes=85</span><br><span class="line"></span><br><span class="line">Input split bytes=236</span><br><span class="line"></span><br><span class="line">Combine input records=8</span><br><span class="line"></span><br><span class="line">Combine output records=6</span><br><span class="line"></span><br><span class="line">Reduce input groups=5</span><br><span class="line"></span><br><span class="line">Reduce shuffle bytes=85</span><br><span class="line"></span><br><span class="line">Reduce input records=6</span><br><span class="line"></span><br><span class="line">Reduce output records=5</span><br><span class="line"></span><br><span class="line">Spilled Records=12</span><br><span class="line"></span><br><span class="line">Shuffled Maps =2</span><br><span class="line"></span><br><span class="line">Failed Shuffles=0</span><br><span class="line"></span><br><span class="line">Merged Map outputs=2</span><br><span class="line"></span><br><span class="line">GC time elapsed (ms)=13</span><br><span class="line"></span><br><span class="line">Total committed heap usage (bytes)=951058432</span><br><span class="line"></span><br><span class="line">Shuffle Errors</span><br><span class="line">BAD_ID=0</span><br><span class="line"></span><br><span class="line">CONNECTION=0</span><br><span class="line"></span><br><span class="line">IO_ERROR=0</span><br><span class="line"></span><br><span class="line">WRONG_LENGTH=0</span><br><span class="line"></span><br><span class="line">WRONG_MAP=0</span><br><span class="line"></span><br><span class="line">WRONG_REDUCE=0</span><br><span class="line"></span><br><span class="line">File Input Format Counters</span><br><span class="line">Bytes Read=48</span><br><span class="line"></span><br><span class="line">File Output Format Counters</span><br><span class="line">Bytes Written=41</span><br><span class="line"></span><br><span class="line">➜  hadoop-2.6.0  bin/hdfs dfs -cat /user/joe/wordcount/output/part-r-00000</span><br><span class="line">16/02/13 01:40:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable（查看结果）</span><br><span class="line"></span><br><span class="line">Bye 1</span><br><span class="line">Goodbye 1</span><br><span class="line">Hadoop 2</span><br><span class="line">Hello 2</span><br><span class="line">World 2</span></span><br></pre></td></tr></table></figure>
<p>java文件：，位置：/hadoop-2.6.0/</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span></span><br><span class="line">       <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span><br><span class="line">                    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span></span><br><span class="line">       <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span><br><span class="line">                       Context context</span><br><span class="line">                       )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      result.set(sum);</span><br><span class="line">      context.write(key, result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">    job.setJarByClass(WordCount.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/06/14/2016-06-18-Hive学习笔记(一)/" rel="next" title="Hive学习笔记(一)">
                <i class="fa fa-chevron-left"></i> Hive学习笔记(一)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/06/18/2016-06-18-Hive总结一/" rel="prev" title="2016-06-18-Hive总结(1)">
                2016-06-18-Hive总结(1) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="liuyiyou" />
          <p class="site-author-name" itemprop="name">liuyiyou</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">75</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories.html">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/liuyiyou" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/people/liuyiyou" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">liuyiyou</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  













  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
